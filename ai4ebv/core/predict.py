"""Functions for model inference."""

# !/usr/bin/env python
# -*- coding: utf-8 -*-

# builtins
import logging
import warnings

# externals
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

# locals
from pysegcnn.core.models import Network
from pysegcnn.core.trainer import LogConfig
from ai4ebv.core.dataset import EoDataset
from ai4ebv.core.legend import Legend
from ai4ebv.core.sample import TrainingDataFactory

# module level logger
LOGGER = logging.getLogger(__name__)


def predict_hls_tile(hls_ts, model, tile_size=(256, 256), features=False,
                     use_indices=False, seasonal=False, dem=None, qa=False):
    """Predict a time series of a HLS tile by division into blocks.

    Parameters
    ----------
    hls_ts : :py:class`xarray.Dataset`
        The HLS image time series as generated by
        :py:meth:`ai4ebv.core.dataset.HLSTimeSeries.to_xarray()`.
    model : :py:class:`pysegcnn.core.models.Network` or
            :py:class:`sklearn.base.ClassifierMixin`
        The model to use for the classification.
    tile_size : `tuple` [`int`], optional
        The spatial size of the blocks that are processed iteratively. The
        default is `(256, 256)`.
    features : `bool`, optional
        Whether to predict using the classification features or the raw time
        series.
    use_indices : `bool`, optional
        Whether to predict using spectral indices in addition to spectra bands.
        The default is `False`.
    seasonal : `bool`, optional
        Whether to use seasonal or annual classification features. The default
        is `False`, which means using annual features.
    dem : `str` or :py:class:`pathlib.Path`, optional
        Digital elevation model for the HLS tile. If specified, the elevation
        of each pixel will be used as an additional feature for classification.
    qa : `bool`, optional
        Whether to apply the quality assessment layer to the time series.

    Returns
    -------
    y_pred : :py:class:`numpy.ndarray`
        The model predictions.
    y_prob : :py:class:`numpy.ndarray`
        The associated model probabilities.

    """
    # helper function
    def reshape_block(block, features=False):
        # reshape data of current block to required shape ---------------------

        # block shape: (bands, ..., y, x)

        # reshape: (bands, ..., nsamples)
        block = block.reshape(*block.shape[0:block.ndim - 2], -1)

        # reshape: (nsamples, ..., bands)
        block = block.swapaxes(0, -1)

        # check whether to predict with raw time series or classification
        # features
        if not features:
            # reshape : (nsamples, nbands, time)
            block = block.swapaxes(1, -1)
        else:
            # reshape : (nsamples, nfeatures)
            block = block.reshape(block.shape[0], -1)

        return block

    # check if model is a neural network
    if isinstance(model, Network):
        # device to compute on: use gpu if available
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        LOGGER.info('Predicting on device: {}'.format(device))

        # check if multiple gpus are available
        if torch.cuda.device_count() > 1:
            LOGGER.info('Using {} available GPUs.'.format(
                torch.cuda.device_count()))
            model = nn.DataParallel(model)

        # send the model to gpu(s) if available and set to evaluation mode
        LOGGER.info('Setting model to evaluation mode ...')
        model = model.to(device)
        model.eval()

    # scale to physical units
    hls_ts = TrainingDataFactory.hls_scale(hls_ts, tile_size)

    # whether to apply the quality assessment layer to the time series
    if qa:
        LOGGER.info('Applying quality assessment layer ...')
        hls_ts = hls_ts.where(~hls_ts.qbin.astype(np.bool), other=np.nan)

    # drop the quality assessment layers
    # hls_ts = hls_ts.drop_vars(['qa', 'qbin'])

    # compute spectral indices
    if use_indices:
        hls_ts = TrainingDataFactory.spectral_indices(hls_ts)

    # replace missing values in time series by median
    hls_ts = hls_ts.where(~np.isnan(hls_ts),
                          other=hls_ts.median(dim='time', skipna=True))

    # whether to use digital elevation model
    if dem is not None:
        # compute digital elevation model features: elevation, slope and aspect
        if features:
            # coordinates: (bands, features, y, x)
            dem_features = TrainingDataFactory.dem_features(dem)
            dem_features = dem_features.expand_dims('features', axis=0)
        else:
            # coordinates: (bands, time, y, x)
            dem_features = TrainingDataFactory.dem_features(
                dem, add_coord={'time': hls_ts.time})

        # convert to dask array
        dem_features = dem_features.to_array().chunk({'x': tile_size[0],
                                                      'y': tile_size[1]}).data

    # predict using time series or classification features --------------------
    if features:
        # compute classification features
        ds = TrainingDataFactory.features(
                hls_ts, TrainingDataFactory.percentiles, seasonal=seasonal)
    else:
        # use whole time series
        ds = hls_ts

    # mask pixels for which not a single observation is valid
    ds = ds.where(~np.isnan(ds), other=-1)
    ds = ds.where(np.isfinite(ds), other=-1)

    # convert to dask arrays
    ds = ds.to_array().chunk({'x': tile_size[0], 'y': tile_size[1]}).data

    # initialize arrays to store model predictions and probabilities
    y_pred = np.ones(ds.shape[-2:], dtype=np.int16) * Legend.NoData.id
    y_prob = np.ones(ds.shape[-2:], dtype=np.float32)

    # iterate over the sub-tiles
    LogConfig.init_log('Initializing prediction.')
    ntiles_rows, ntiles_cols = ds.numblocks[-2], ds.numblocks[-1]
    LOGGER.info('Number of blocks: {}'.format((ntiles_rows, ntiles_cols)))
    for row in range(ntiles_rows):
        for col in range(ntiles_cols):
            LOGGER.info('Predicting block: {}'.format((row + 1, col + 1)))

            # load the current sub-tile into memory ---------------------------
            with warnings.catch_warnings():
                warnings.simplefilter('ignore', category=RuntimeWarning)
                tile = ds.blocks[..., row, col].compute()
            tile_shape = tile.shape

            # array coordinates of the current block
            tl = (row * tile_size[0], col * tile_size[1])
            br = (tl[0] + tile_shape[-2], tl[1] + tile_shape[-1])

            # reshape input data to required shape ----------------------------
            tile = reshape_block(tile, features)

            # check whether to add digital elevation model features -----------
            if dem is not None:
                dem_tile = dem_features.blocks[..., row, col].compute()
                dem_tile = reshape_block(dem_tile, features)

                # add digital elevation model features
                tile = np.concatenate((tile, dem_tile), axis=1)

            # model predictions: PyTorch or Sklearn ---------------------------
            if isinstance(model, Network) | isinstance(model, nn.DataParallel):

                # convert tile data to torch tensor and send to gpu if
                # available
                tile = EoDataset.to_tensor(tile, torch.float32).to(device)

                # calculate network predictions
                with torch.no_grad():
                    logits = model(tile)

                # calculate output labels and associated probabilities: PyTorch
                pred = F.softmax(logits, dim=1).max(dim=1)
                y = pred.indices.cpu().numpy()
                p = pred.values.cpu().numpy()
            else:
                # calculate output labels and associated probabilities: Sklearn
                y = model.predict(tile)
                p = model.predict_proba(tile).max(axis=1)

            # write model output to array
            y_pred[tl[0]:br[0], tl[1]:br[1]] = y.reshape(tile_shape[-2:])
            y_prob[tl[0]:br[0], tl[1]:br[1]] = p.reshape(tile_shape[-2:])

    return y_pred, y_prob
